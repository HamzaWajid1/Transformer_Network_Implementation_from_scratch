{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q-query vector: What I am looking for\n",
    "k-key vector: What I can offer\n",
    "v-value vector: what I actually offer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=4 #length of sentence\n",
    "batch_size=1\n",
    "input_dim=512\n",
    "d_model=512\n",
    "x=torch.randn((batch_size,seq_len,input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that x is not the value of the input but the value that we get after input embedding. In this case its taken rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1536, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#done to create q k and v vectors concatinated\n",
    "qkv_layer=nn.Linear(input_dim,3*d_model)\n",
    "qkv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1451,  1.3501,  1.1285,  ...,  0.5574, -0.4863, -0.6798],\n",
       "         [ 0.2442, -1.0424, -0.0583,  ..., -0.4577,  0.4065,  0.1546],\n",
       "         [-0.9975,  0.1986, -0.1687,  ..., -0.9849, -0.3517, -0.6339],\n",
       "         [ 0.9389, -0.5585,  1.2884,  ..., -0.3924,  0.2324,  0.0486]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv=qkv_layer(x)\n",
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads=8\n",
    "head_dim=d_model //num_heads\n",
    "qkv=qkv.reshape(batch_size,seq_len,num_heads,3*head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv=qkv.permute(0,2,1,3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v=qkv.chunk(3,dim=-1)\n",
    "q.shape , k.shape , v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 4]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 64, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k=q.size()[-1]\n",
    "scaled=torch.matmul(q,k.transpose(-2,-1))/ math.sqrt(d_k)\n",
    "scaled.shape , q.shape, k.transpose(-2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=torch.full(scaled.size(),float('-inf'))\n",
    "mask=torch.triu(mask,diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1988,    -inf,    -inf,    -inf],\n",
       "        [ 0.0669,  0.0051,    -inf,    -inf],\n",
       "        [-0.2175,  0.0596, -0.2197,    -inf],\n",
       "        [ 0.0235, -0.3644,  0.0372, -0.1524]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled+mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled=scaled+mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention=F.softmax(scaled,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5154, 0.4846, 0.0000, 0.0000],\n",
       "          [0.3015, 0.3977, 0.3008, 0.0000],\n",
       "          [0.2832, 0.1921, 0.2871, 0.2375]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4864, 0.5136, 0.0000, 0.0000],\n",
       "          [0.2335, 0.4124, 0.3542, 0.0000],\n",
       "          [0.3559, 0.2032, 0.3044, 0.1364]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5932, 0.4068, 0.0000, 0.0000],\n",
       "          [0.5446, 0.1379, 0.3175, 0.0000],\n",
       "          [0.2160, 0.2580, 0.3220, 0.2040]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4644, 0.5356, 0.0000, 0.0000],\n",
       "          [0.2361, 0.4223, 0.3416, 0.0000],\n",
       "          [0.3288, 0.2533, 0.1679, 0.2501]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4354, 0.5646, 0.0000, 0.0000],\n",
       "          [0.2372, 0.4132, 0.3496, 0.0000],\n",
       "          [0.2230, 0.3422, 0.1056, 0.3293]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6937, 0.3063, 0.0000, 0.0000],\n",
       "          [0.5090, 0.3181, 0.1729, 0.0000],\n",
       "          [0.2489, 0.2104, 0.3215, 0.2192]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4675, 0.5325, 0.0000, 0.0000],\n",
       "          [0.1693, 0.4013, 0.4294, 0.0000],\n",
       "          [0.2923, 0.3421, 0.2516, 0.1141]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4609, 0.5391, 0.0000, 0.0000],\n",
       "          [0.2348, 0.4906, 0.2746, 0.0000],\n",
       "          [0.1914, 0.1627, 0.5175, 0.1284]]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values=torch.matmul(attention,v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attention.shape\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5154, 0.4846, 0.0000, 0.0000],\n",
       "        [0.3015, 0.3977, 0.3008, 0.0000],\n",
       "        [0.2832, 0.1921, 0.2871, 0.2375]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values = values.reshape(batch_size, seq_len, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1513,  0.1235,  0.2849,  ..., -0.2099,  0.5354, -0.0492],\n",
       "         [ 0.0939, -0.3143,  0.1780,  ...,  0.0615,  0.1062,  0.3315],\n",
       "         [-0.4269, -0.1941,  0.2890,  ...,  0.4284, -0.0590, -0.0972],\n",
       "         [ 0.2177,  0.3734,  0.1209,  ..., -0.2225, -0.0388,  0.0582]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
