{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hamza\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(attention, self).__init__()\n",
    "        self.embed_size=embed_size\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim= embed_size // num_heads\n",
    "\n",
    "        assert(self.head_dim * num_heads == embed_size), \"Embed size must be completely divisible by number of heads\"\n",
    "\n",
    "        self.query=nn.Linear(self.head_dim,self.head_dim,bias=False)\n",
    "        self.key=nn.Linear(self.embed_size,self.head_dim,bias=False)\n",
    "        self.value=nn.Linear(self.embed_size,self.head_dim,bias=False)\n",
    "        self.output=nn.Linear(num_heads*self.head_dim,embed_size)\n",
    "\n",
    "    def forward(self,query,key,value,mask):\n",
    "        batch_size=query.shape[0]\n",
    "        q_len,k_len,v_len=query.shape[1],key.shape[1],value.shape[1]\n",
    "        print(\"\\n\\n\\nThe shapes before permutetion\")\n",
    "        query=query.reshape(batch_size,q_len,self.num_heads,self.head_dim)\n",
    "        print(\"The shape of query is \"+str(query.shape))\n",
    "        key=key.reshape(batch_size,k_len,self.num_heads,self.head_dim)\n",
    "        print(\"The shape of key is \"+str(key.shape))\n",
    "        value=value.reshape(batch_size,v_len,self.num_heads,self.head_dim)\n",
    "        print(\"The shape of value is \"+str(value.shape))\n",
    "        # Transpose to perform batch matrix multiplication\n",
    "        query = query.permute(0, 2, 1, 3)  # (batch_size, num_heads, q_len, head_dim)\n",
    "        key = key.permute(0, 2, 1, 3)  # (batch_size, num_heads, k_len, head_dim)\n",
    "        value = value.permute(0, 2, 1, 3)  # (batch_size, num_heads, v_len, head_dim)\n",
    "        print(\"\\n\\n\\nThe shapes after permutetion\")\n",
    "        print(\"The shape of query is \"+str(query.shape))\n",
    "        print(\"The shape of key is \"+str(key.shape))\n",
    "        print(\"The shape of value is \"+str(value.shape))\n",
    "        # Calculate attention scores\n",
    "        scores = torch.matmul(query, key.transpose(-2,-1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            mask1=torch.full(scores.size(),float('-inf'))\n",
    "            #print(mask1)\n",
    "            mask1=torch.triu(mask1,diagonal=1)\n",
    "            #print(mask1)\n",
    "            #print(scores)\n",
    "            scores += mask1\n",
    "            #print(scores)\n",
    "        \n",
    "        # Apply softmax to obtain attention weights\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        # Apply dropout if needed (you can add this if desired)\n",
    "        # attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # Apply attention weights to the values\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        print(\"The initial shape of output is \"+str(output.shape))\n",
    "        # Reshape and concatenate heads\n",
    "        output = output.permute(0, 2, 1, 3).contiguous()  # (batch_size, q_len, num_heads, head_dim)\n",
    "        output = output.reshape(batch_size, q_len, self.num_heads * self.head_dim)\n",
    "        \n",
    "        # Linear transformation to get the final output\n",
    "        output = self.output(output)\n",
    "        print(\"The final shape of output is \"+str(output.shape))\n",
    "        return output        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 3, 2, 4])\n",
      "The shape of key is torch.Size([2, 3, 2, 4])\n",
      "The shape of value is torch.Size([2, 3, 2, 4])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 2, 3, 4])\n",
      "The shape of key is torch.Size([2, 2, 3, 4])\n",
      "The shape of value is torch.Size([2, 2, 3, 4])\n",
      "The initial shape of output is torch.Size([2, 2, 3, 4])\n",
      "The final shape of output is torch.Size([2, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate the Attention class\n",
    "embed_size = 8\n",
    "num_heads = 2\n",
    "attention_model = attention(embed_size, num_heads)\n",
    "\n",
    "# Define a sample input\n",
    "batch_size = 2\n",
    "q_len = 3\n",
    "k_len = 3\n",
    "v_len = 3\n",
    "\n",
    "# Create random tensors as input\n",
    "query = torch.randn(batch_size, q_len, embed_size)\n",
    "key = torch.randn(batch_size, k_len, embed_size)\n",
    "value = torch.randn(batch_size, v_len, embed_size)\n",
    "\n",
    "# Define a sample mask (you can modify this based on your use case)\n",
    "mask = 1  # Assuming a fully-connected attention\n",
    "\n",
    "# Call the forward method\n",
    "output = attention_model.forward(query, key, value, mask)\n",
    "\n",
    "# Print the output shape\n",
    "#print(\"Output Shape:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size,num_heads,dropout,foward_expansion):\n",
    "        super(TransformerBlock,self).__init__()\n",
    "        self.attention=attention(embed_size,num_heads=num_heads)\n",
    "        self.norm1=nn.LayerNorm(embed_size)\n",
    "        self.norm2=nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_foward=nn.Sequential(\n",
    "            nn.Linear(embed_size,foward_expansion*embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(foward_expansion*embed_size,embed_size)\n",
    "        )\n",
    "\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,query,key,value,mask):\n",
    "        multi_head_attention=self.attention(query,key,value,mask)\n",
    "        x=self.dropout(self.norm1(multi_head_attention+query))\n",
    "        foward=self.feed_foward(x)  \n",
    "        out=self.dropout(self.norm2(foward + x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding1(nn.Module):\n",
    "    def __init__(self, max_len, embed_size):\n",
    "        super(PositionalEncoding1, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # Create constant positional encoding matrix\n",
    "        pe = torch.zeros(max_len, embed_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure that positional encoding has the same shape as input tensor x\n",
    "        batch_size, seq_len = x.shape[:2]\n",
    "        pe = self.pe[:, :seq_len, :].expand(batch_size, -1, -1)\n",
    "        return pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_vocab_size,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 device,\n",
    "                 foward_expansion,\n",
    "                 dropout,\n",
    "                 max_length \n",
    "                ):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embed_size=embed_size\n",
    "        self.device=device\n",
    "        self.input_embedding=nn.Embedding(src_vocab_size,embed_size)\n",
    "        self.positional_encoding=PositionalEncoding1(max_length,embed_size)\n",
    "\n",
    "        self.layers=nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(embed_size,num_heads,dropout,foward_expansion)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        batch_size,seq_len=x.shape\n",
    "        print(\"Batch size is : \"+str(batch_size))\n",
    "        print(\"Seq length is : \"+str(seq_len)),\n",
    "\n",
    "        embedding=self.input_embedding(x)\n",
    "        #print(\"input embedding is :\\n\\n\\n \"+str(embedding)),\n",
    "        print(\"\\n\\n\\nInput embedding shape is :\\n\\n\\n \"+str(embedding.shape)),\n",
    "#        positions=torch.arange(0,seq_len).expand(batch_size,seq_len).to(device=self.device)\n",
    "        #print(\"Position is :\\n\\n\\n \"+str(positions)),\n",
    "        #print(\"\\n\\n\\nPosition shape is :\\n\\n\\n \"+str(positions.shape)),\n",
    "        # Generate positional encoding dynamically based on the input sequence length\n",
    "        positional_encoding = self.positional_encoding(x)\n",
    "        #positional_encoding = positional_encoding.unsqueeze(0).expand(1,batch_size, embed_size, embed_size)\n",
    "        #print(\"Positional encoding is :\\n\\n\\n \"+str(positional_encoding)),\n",
    "        print(\"\\n\\n\\nPositional encoding shape is :\\n\\n\\n \"+str(positional_encoding.shape)),\n",
    "        \n",
    "        #out=self.dropout(self.input_embedding(x)+self.positional_encoding(positions))\n",
    "        out=self.dropout(embedding+positional_encoding)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            out=layer(out,out,out,mask)\n",
    "        return out    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is : 2\n",
      "Seq length is : 20\n",
      "\n",
      "\n",
      "\n",
      "Input embedding shape is :\n",
      "\n",
      "\n",
      " torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "Positional encoding shape is :\n",
      "\n",
      "\n",
      " torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 20, 8, 16])\n",
      "The shape of key is torch.Size([2, 20, 8, 16])\n",
      "The shape of value is torch.Size([2, 20, 8, 16])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 20, 16])\n",
      "The shape of key is torch.Size([2, 8, 20, 16])\n",
      "The shape of value is torch.Size([2, 8, 20, 16])\n",
      "The initial shape of output is torch.Size([2, 8, 20, 16])\n",
      "The final shape of output is torch.Size([2, 20, 128])\n",
      "Encoder output shape: torch.Size([2, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "# Toy dataset (replace with your dataset)\n",
    "src_vocab_size = 200  # Example vocabulary size\n",
    "max_length = 20  # Example maximum sequence length\n",
    "num_layers = 8\n",
    "embed_size = 128\n",
    "num_heads = 8\n",
    "forward_expansion = 4\n",
    "dropout = 0.2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = Encoder(src_vocab_size, embed_size, num_layers, num_heads, device, forward_expansion, dropout, max_length)\n",
    "\n",
    "# Generate some sample input data\n",
    "sample_input = torch.randint(0, src_vocab_size, (2, max_length))  # Batch size 2, sequence length 20\n",
    "sample_mask = torch.ones_like(sample_input)\n",
    "\n",
    "# Pass the input data through the encoder\n",
    "encoder_output = encoder(sample_input, sample_mask)\n",
    "\n",
    "# Check the output shape\n",
    "print(\"Encoder output shape:\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_block(nn.Module):\n",
    "    def __init__(self,embed_size,num_heads,forward_expansion,dropout,device):\n",
    "        super(Decoder_block,self).__init__()\n",
    "        self.multi_head_attention=attention(embed_size,num_heads)\n",
    "        self.norm=nn.LayerNorm(embed_size)\n",
    "        self.transformer_block=TransformerBlock(embed_size,num_heads,dropout,forward_expansion)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x,key,value,src_mask,targ_mask):\n",
    "        multi_head_attention=self.multi_head_attention(x,x,x,targ_mask)\n",
    "        query=self.dropout(self.norm(x+multi_head_attention))\n",
    "        out=self.transformer_block(query,key,value,src_mask)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            target_vocab_size,\n",
    "            embed_size,\n",
    "            num_heads,\n",
    "            num_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length\n",
    "\n",
    "    ):\n",
    "        super(decoder,self).__init__()\n",
    "        self.device=device\n",
    "        self.word_embedding=nn.Embedding(target_vocab_size,embed_size)\n",
    "        self.positional_encoding=PositionalEncoding1(max_length,embed_size)\n",
    "\n",
    "        self.layers=nn.ModuleList(\n",
    "            [\n",
    "                Decoder_block(embed_size,num_heads,forward_expansion,dropout,device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out=nn.Linear(embed_size,target_vocab_size)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x,enc_out,src_mask,trg_mask):\n",
    "        input_embedding=self.word_embedding(x)\n",
    "        positional_encoding=self.positional_encoding(x)\n",
    "\n",
    "        x=self.dropout(input_embedding+positional_encoding)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,enc_out,enc_out,src_mask,trg_mask)\n",
    "\n",
    "            out=self.fc_out(x)\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            src_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            #src_pad_index,\n",
    "            #trg_pad_index,\n",
    "            embed_size=768,\n",
    "            num_layers=6,\n",
    "            forward_expansion=4,\n",
    "            num_heads=8,\n",
    "            dropout=0,\n",
    "            device=\"cuda\",\n",
    "            max_length=100,\n",
    "            enc_mask=None,\n",
    "            dec_mask=1\n",
    "            \n",
    "\n",
    "    ):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.encoder=Encoder(src_vocab_size,embed_size,num_layers,num_heads,device,forward_expansion,dropout,max_length)\n",
    "        self.decoder=decoder(trg_vocab_size,embed_size,num_heads,num_layers,forward_expansion,dropout,device,max_length)\n",
    "        #self.src_pad_index=src_pad_index\n",
    "        #self.trg_pad_index=trg_pad_index\n",
    "        self.device=device\n",
    "    \n",
    "\n",
    "    def forward(self,src,trg):\n",
    "        enc_src=self.encoder(src,None)\n",
    "        print(\"\\n\\n\\n\\nThe shape of encoder is \"+str(enc_src.shape))\n",
    "        out=self.decoder(trg,enc_src,None,1)\n",
    "        print(\"\\n\\n\\n\\nThe shape of output is \"+str(out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x=torch.tensor([[1,5,6,4,3,9,5,2,8],[1,8,7,3,4,5,6,7,2]])\n",
    "trg=torch.tensor([[1,7,4,3,5,9,2,0],[1,5,6,2,4,7,6,2]]).to(device)\n",
    "\n",
    "model=Transformer(768,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is : 2\n",
      "Seq length is : 9\n",
      "\n",
      "\n",
      "\n",
      "Input embedding shape is :\n",
      "\n",
      "\n",
      " torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "Positional encoding shape is :\n",
      "\n",
      "\n",
      " torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 9, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 9, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 9, 32])\n",
      "The final shape of output is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The shape of encoder is torch.Size([2, 9, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 7, 8, 32])\n",
      "The shape of value is torch.Size([2, 7, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 7, 32])\n",
      "The shape of value is torch.Size([2, 8, 7, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "The shapes before permutetion\n",
      "The shape of query is torch.Size([2, 7, 8, 32])\n",
      "The shape of key is torch.Size([2, 9, 8, 32])\n",
      "The shape of value is torch.Size([2, 9, 8, 32])\n",
      "\n",
      "\n",
      "\n",
      "The shapes after permutetion\n",
      "The shape of query is torch.Size([2, 8, 7, 32])\n",
      "The shape of key is torch.Size([2, 8, 9, 32])\n",
      "The shape of value is torch.Size([2, 8, 9, 32])\n",
      "The initial shape of output is torch.Size([2, 8, 7, 32])\n",
      "The final shape of output is torch.Size([2, 7, 256])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The shape of output is torch.Size([2, 7, 10])\n"
     ]
    }
   ],
   "source": [
    "output=model(x,trg[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9224,  0.1032,  0.5054,  1.0900, -0.1421, -0.4101, -0.0539,\n",
       "          -0.8155,  0.2523,  0.0597],\n",
       "         [ 0.3218,  0.0696,  0.7126,  1.1054, -0.0599,  0.0030, -0.1660,\n",
       "          -0.6135,  0.1673,  0.0881],\n",
       "         [ 0.7556, -0.3133, -0.1340,  0.5877, -0.2255, -0.1921, -0.6670,\n",
       "          -1.3984,  0.5521,  0.2703],\n",
       "         [ 1.0037, -0.5307,  0.3663,  0.6399, -0.4201, -0.4295, -0.3950,\n",
       "          -1.3853,  0.4437,  0.3500],\n",
       "         [ 0.6039, -0.4387,  0.4118,  0.5748, -0.1682, -0.4041, -0.3428,\n",
       "          -1.2708,  0.1850,  0.2073],\n",
       "         [ 0.8007, -0.4222, -0.0172,  0.6110, -0.2957, -0.3175, -0.1543,\n",
       "          -1.0654,  0.2906,  0.1814],\n",
       "         [ 0.6212, -0.1921, -0.2053,  1.1558, -0.2308, -0.5708,  0.0368,\n",
       "          -1.0455, -0.0085,  0.5203]],\n",
       "\n",
       "        [[ 0.9226, -0.0695,  0.2646,  1.2175, -0.0387, -0.6737, -0.4489,\n",
       "          -1.2014,  0.5484,  0.0328],\n",
       "         [ 0.7070, -0.3851,  0.0673,  0.6884,  0.0889, -0.6300, -0.4935,\n",
       "          -1.5010,  0.4247, -0.1440],\n",
       "         [ 1.0756, -0.1376,  0.1255,  0.9048, -0.0338, -0.4820, -0.2631,\n",
       "          -1.6769,  0.5201, -0.7936],\n",
       "         [ 0.9213, -0.1702, -0.2804,  1.3571, -0.0212, -0.9335, -0.1064,\n",
       "          -1.3018,  0.3429,  0.4207],\n",
       "         [ 0.9559, -0.5101, -0.1616,  0.7177, -0.1445, -0.7454, -0.7683,\n",
       "          -1.5910,  0.9819, -0.0390],\n",
       "         [ 0.3994, -0.3290,  0.2405,  1.2595,  0.0904, -0.4538, -0.7509,\n",
       "          -1.2793,  0.4943,  0.1402],\n",
       "         [ 0.9504, -0.4091,  0.1103,  0.9739, -0.2225, -0.4136, -0.4060,\n",
       "          -1.7399,  0.6071, -0.5464]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"Hello, how are you doing today?\"\n",
    "\n",
    "# Tokenize input sentence\n",
    "tokenized_input = tokenizer(input_sentence, return_tensors='pt')\n",
    "\n",
    "# Get tokenized input IDs\n",
    "input_ids = tokenized_input['input_ids']\n",
    "\n",
    "# Forward pass through BERT model to get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_input)\n",
    "\n",
    "# Get the embeddings from BERT's output\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Print shape of the embeddings\n",
    "print(\"Embeddings shape:\", last_hidden_states.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = nn.ReLU()  # Using ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear transformation\n",
    "        linear_output = self.linear(x)\n",
    "        # Apply activation function\n",
    "        output = self.activation(linear_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearModel(768, 64)\n",
    "output = linear_model(last_hidden_states)\n",
    "output.shape\n",
    "output=output.squeeze(0)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding() missing 1 required positional argument: 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m a\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding() missing 1 required positional argument: 'weight'"
     ]
    }
   ],
   "source": [
    "a=PositionalEncoding1()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 2725, 2651, 1029,  102]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0050, -0.0445, -0.2543,  ..., -0.4674,  0.1839,  0.4307],\n",
       "         [ 0.1518, -0.3346,  0.0500,  ..., -0.0397,  0.9728,  0.3340],\n",
       "         [-0.5165,  0.2028,  0.5212,  ..., -0.5615,  0.4370,  0.1435],\n",
       "         ...,\n",
       "         [-0.2533, -0.7244, -0.7809,  ..., -0.1901, -0.0070, -0.6356],\n",
       "         [-0.3863, -0.8991, -0.8409,  ...,  0.0749,  0.1376, -0.1122],\n",
       "         [ 0.5416, -0.1070, -0.3464,  ...,  0.1287, -0.4294, -0.2204]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Input shape: torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "# Reshape the embeddings to match the input shape of the transformer\n",
    "transformer_input = last_hidden_states.squeeze(0)  # Remove the batch dimension\n",
    "#transformer_input = transformer_input.transpose(0, 1)  # Transpose to match [sequence_length, batch_size]\n",
    "\n",
    "# Print the shape of the transformer input\n",
    "print(\"Transformer Input shape:\", transformer_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x=torch.tensor([[1,5,6,4,3,9,5,2,8],[1,8,7,3,4,5,6,7,2]])\n",
    "trg=torch.tensor([[1,7,4,3,5,9,2,0],[1,5,6,2,4,7,6,2]]).to(device)\n",
    "\n",
    "model=Transformer(64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is : 10\n",
      "Seq length is : 768\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output1\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 29\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,src,trg):\n\u001b[1;32m---> 29\u001b[0m     enc_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe shape of encoder is \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(enc_src\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m     31\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(trg,enc_src,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 31\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size is : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(batch_size))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq length is : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(seq_len)),\n\u001b[1;32m---> 31\u001b[0m embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#print(\"input embedding is :\\n\\n\\n \"+str(embedding)),\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput embedding shape is :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(embedding\u001b[38;5;241m.\u001b[39mshape)),\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "output1=model(transformer_input,trg[:,:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
