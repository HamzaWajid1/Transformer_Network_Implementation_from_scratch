{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.Layers import EncoderLayer, DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.Models import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, bert_model_name, input_embedding_size, d_model, n_layers, n_head, d_k, d_v,\n",
    "            d_inner, dropout=0.1, max_sequence_length=512):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # Initialize BERT tokenizer and model\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        # Input embedding layer\n",
    "        self.input_embedding = nn.Linear(self.bert_model.config.hidden_size, input_embedding_size)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(input_embedding_size, max_sequence_length)\n",
    "\n",
    "        # Multi-layer Transformer encoder\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_texts):\n",
    "\n",
    "        input_ids = self.bert_tokenizer(input_texts, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        print(input_ids)\n",
    "        # BERT tokenization and embedding\n",
    "        bert_outputs = self.bert_model(input_ids)[0]  # (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Input embedding\n",
    "        input_embedding = self.input_embedding(bert_outputs)  # (batch_size, seq_length, input_embedding_size)\n",
    "\n",
    "        # Positional encoding\n",
    "        positional_encoded_input = self.positional_encoding(input_embedding)  # (batch_size, seq_length, input_embedding_size)\n",
    "\n",
    "        # Multi-layer Transformer encoder\n",
    "        encoder_output = positional_encoded_input\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoder_output = encoder_layer(encoder_output)  # (batch_size, seq_length, d_model)\n",
    "\n",
    "        return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_outputs = bert_model(input_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3eb3ce264504705820a7d722b685a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7f26ebe82240df884f3dd20ea6b788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd7bc56d3404c86988545ca3ef4606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e7116a2a734100a27e2e9894ae4a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560122a64c4e469cafc83f80975bba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     20\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Encoder(\n\u001b[0;32m     21\u001b[0m     bert_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     input_embedding_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,  \u001b[38;5;66;03m# Set input embedding size as per your requirement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     max_sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m  \u001b[38;5;66;03m# Maximum sequence length\u001b[39;00m\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Step 5: Pass input tensor through the encoder\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Step 6: Inspect the encoder output\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder_output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     34\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m positional_encoded_input\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers:\n\u001b[1;32m---> 36\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_length, d_model)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hamza\\OneDrive\\Desktop\\Chat_Bot_dev_Versions\\attention\\transformer\\Layers.py:19\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, enc_input, slf_attn_mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_input, slf_attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     enc_output, enc_slf_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslf_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslf_attn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ffn(enc_output)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enc_output, enc_slf_attn\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hamza\\OneDrive\\Desktop\\Chat_Bot_dev_Versions\\attention\\transformer\\SubLayers.py:33\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, k, v, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     d_k, d_v, n_head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head\n\u001b[1;32m---> 33\u001b[0m     sz_b, len_q, len_k, len_v \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m), q\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     residual \u001b[38;5;241m=\u001b[39m q\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Pass through the pre-attention projection: b x lq x (n*dv)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Separate different heads: b x lq x n x dv\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "#from your_module import Encoder  # Import the Encoder class from your module\n",
    "\n",
    "# Define sample sentence\n",
    "sample_sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# Step 1: Tokenize the sample sentence using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_sentence = tokenizer.encode(sample_sentence, add_special_tokens=True)\n",
    "\n",
    "# Step 2: Convert tokenized sentence into token IDs\n",
    "input_ids = torch.tensor([tokenized_sentence])\n",
    "\n",
    "# Step 3: Prepare input tensor with batch dimension\n",
    "input_tensor = input_ids  # No need to add batch dimension as input is already batched\n",
    "\n",
    "# Step 4: Instantiate the Encoder\n",
    "encoder = Encoder(\n",
    "    bert_model_name=\"bert-base-uncased\",\n",
    "    input_embedding_size=512,  # Set input embedding size as per your requirement\n",
    "    d_model=512,  # Set d_model as per your requirement\n",
    "    n_layers=6,  # Number of encoder layers\n",
    "    n_head=8,  # Number of attention heads\n",
    "    d_k=64,  # Dimensionality of key vectors\n",
    "    d_v=64,  # Dimensionality of value vectors\n",
    "    d_inner=2048,  # Dimensionality of inner-layer in feed-forward network\n",
    "    dropout=0.1,  # Dropout probability\n",
    "    max_sequence_length=512  # Maximum sequence length\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Instantiate the Encoder\n",
    "encoder = Encoder(\n",
    "    bert_model_name=\"bert-base-uncased\",\n",
    "    input_embedding_size=512,  # Set input embedding size as per your requirement\n",
    "    d_model=512,  # Set d_model as per your requirement\n",
    "    n_layers=6,  # Number of encoder layers\n",
    "    n_head=8,  # Number of attention heads\n",
    "    d_k=64,  # Dimensionality of key vectors\n",
    "    d_v=64,  # Dimensionality of value vectors\n",
    "    d_inner=2048,  # Dimensionality of inner-layer in feed-forward network\n",
    "    dropout=0.1,  # Dropout probability\n",
    "    max_sequence_length=512  # Maximum sequence length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Pass input tensor through the encoder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMy name is Hamza\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 6: Inspect the encoder output\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder_output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# BERT tokenization and embedding\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     bert_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Input embedding\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     input_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_embedding(bert_outputs)  \u001b[38;5;66;03m# (batch_size, seq_length, input_embedding_size)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py:4351\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4350\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4352\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4356\u001b[0m     )\n\u001b[0;32m   4358\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4359\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'tuple'"
     ]
    }
   ],
   "source": [
    "# Step 5: Pass input tensor through the encoder\n",
    "encoder_output = encoder(\"My name is Hamza\")\n",
    "\n",
    "# Step 6: Inspect the encoder output\n",
    "print(\"Encoder output shape:\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder\n",
    "encoder = Encoder(bert_model_name='bert-base-uncased',\n",
    "                  input_embedding_size=512,\n",
    "                  d_model=512,\n",
    "                  n_layers=5,\n",
    "                  n_head=8,\n",
    "                  d_k=64,\n",
    "                  d_v=64,\n",
    "                  d_inner=2048,\n",
    "                  dropout=0.1,\n",
    "                  max_sequence_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2026,  2171,  2003, 10654,  4143,   102]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define input text\n",
    "input_text = \"my name is hamza\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = encoder.bert_tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Pass through the encoder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print output shape\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder_output\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# BERT tokenization and embedding\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     bert_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Input embedding\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     input_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_embedding(bert_outputs)  \u001b[38;5;66;03m# (batch_size, seq_length, input_embedding_size)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py:4351\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4350\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4352\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4356\u001b[0m     )\n\u001b[0;32m   4358\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4359\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'tuple'"
     ]
    }
   ],
   "source": [
    "# Pass through the encoder\n",
    "encoder_output = encoder.forward(input_text)\n",
    "\n",
    "# Print output shape\n",
    "print(\"Encoder output shape:\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     34\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m positional_encoded_input\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers:\n\u001b[1;32m---> 36\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_length, d_model)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hamza\\OneDrive\\Desktop\\Chat_Bot_dev_Versions\\attention\\transformer\\Layers.py:19\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, enc_input, slf_attn_mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_input, slf_attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     enc_output, enc_slf_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslf_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslf_attn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ffn(enc_output)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enc_output, enc_slf_attn\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hamza\\OneDrive\\Desktop\\Chat_Bot_dev_Versions\\attention\\transformer\\SubLayers.py:33\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, k, v, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     d_k, d_v, n_head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head\n\u001b[1;32m---> 33\u001b[0m     sz_b, len_q, len_k, len_v \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m), q\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     residual \u001b[38;5;241m=\u001b[39m q\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Pass through the pre-attention projection: b x lq x (n*dv)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Separate different heads: b x lq x n x dv\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "encoder_output = encoder(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2023, 2003, 1037, 7099, 6251, 1012,  102]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Transformer model\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src_seq, trg_seq):\n",
    "        enc_output, _ = self.encoder(src_seq)\n",
    "        dec_output = self.decoder(trg_seq, enc_output)\n",
    "        return dec_output\n",
    "\n",
    "# Define the training function\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for src_seq, trg_seq in dataloader:\n",
    "        src_seq, trg_seq = src_seq.to(device), trg_seq.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src_seq, trg_seq[:-1])  # Ignore <eos> token in target\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg_seq = trg_seq[1:].contiguous().view(-1)  # Ignore <sos> token in target\n",
    "\n",
    "        loss = criterion(output, trg_seq)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Define your Transformer model\n",
    "    encoder = Encoder(...)\n",
    "    decoder = Decoder(...)\n",
    "    model = Transformer(encoder, decoder)\n",
    "\n",
    "    # Define your dataloader\n",
    "    dataloader = DataLoader(...)\n",
    "\n",
    "    # Define your optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, dataloader, optimizer, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from torch import nn\n",
    "\n",
    "# Import transformer encoder layer\n",
    "from transformers.models.bert.modeling_bert import BertEncoder, BertLayer\n",
    "\n",
    "# Import positional encoding functions\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't find a vocabulary file at path 'my name is hamza'. To load the vocabulary from a Google pretrained model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy name is hamza\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tokenize input text\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mBertTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m input_ids\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:200\u001b[0m, in \u001b[0;36mBertTokenizer.__init__\u001b[1;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     vocab_file,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    198\u001b[0m ):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(vocab_file):\n\u001b[1;32m--> 200\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a vocabulary file at path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. To load the vocabulary from a Google pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         )\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m load_vocab(vocab_file)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids_to_tokens \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict([(ids, tok) \u001b[38;5;28;01mfor\u001b[39;00m tok, ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mitems()])\n",
      "\u001b[1;31mValueError\u001b[0m: Can't find a vocabulary file at path 'my name is hamza'. To load the vocabulary from a Google pretrained model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`"
     ]
    }
   ],
   "source": [
    "# Define input text\n",
    "input_text = \"my name is hamza\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = BertTokenizer(input_text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenize the sample sentence using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample sentence\n",
    "sample_sentence = \"My name is Hamza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.encode(sample_sentence, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert tokenized sentence into token IDs\n",
    "input_ids = torch.tensor([tokenized_sentence])\n",
    "\n",
    "# Step 3: Prepare input tensor with batch dimension\n",
    "input_tensor = input_ids  # No need to add batch dimension as input is already batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=bert_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1111,  0.5129, -0.2334,  ..., -0.1131,  0.0528,  0.4727],\n",
       "         [ 0.0246, -0.1088, -0.6136,  ..., -0.2063, -0.0297,  0.1686],\n",
       "         [-0.3681,  0.4598,  0.0354,  ..., -0.3725,  0.2379,  0.1640],\n",
       "         ...,\n",
       "         [-0.1694,  0.1914, -0.0478,  ..., -0.6429, -0.2118, -0.3504],\n",
       "         [-0.3843, -0.3724, -0.4704,  ...,  0.5174, -0.0247, -0.5458],\n",
       "         [ 0.8794,  0.0940, -0.3478,  ...,  0.1397, -0.7686, -0.2198]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-9.0945e-01, -5.6075e-01, -6.4941e-01,  8.0342e-01,  6.8100e-01,\n",
       "         -1.5603e-01,  8.8296e-01,  4.1021e-01, -5.0835e-01, -9.9997e-01,\n",
       "         -3.3631e-01,  9.3180e-01,  9.8704e-01,  3.5370e-01,  9.5970e-01,\n",
       "         -8.0688e-01, -2.7589e-01, -6.7485e-01,  4.2549e-01, -4.5297e-01,\n",
       "          7.3032e-01,  9.9993e-01,  3.0233e-01,  4.1703e-01,  5.2074e-01,\n",
       "          9.7937e-01, -7.6852e-01,  9.5116e-01,  9.7300e-01,  7.7292e-01,\n",
       "         -6.7838e-01,  3.0296e-01, -9.9352e-01, -2.1164e-01, -6.4044e-01,\n",
       "         -9.9205e-01,  5.0435e-01, -7.9071e-01, -2.0878e-01, -3.3872e-02,\n",
       "         -9.4653e-01,  3.9237e-01,  9.9993e-01, -4.8753e-01,  4.5299e-01,\n",
       "         -3.9425e-01, -1.0000e+00,  3.7851e-01, -9.1112e-01,  7.6742e-01,\n",
       "          6.7790e-01,  6.8021e-01,  3.1301e-01,  5.0331e-01,  5.7257e-01,\n",
       "         -2.6097e-01, -1.3139e-04,  2.1676e-01, -3.3315e-01, -6.4578e-01,\n",
       "         -7.0713e-01,  5.0816e-01, -7.9232e-01, -9.0362e-01,  6.8143e-01,\n",
       "          4.8374e-01, -3.3194e-01, -3.7780e-01, -1.7803e-01,  7.6889e-02,\n",
       "          9.1376e-01,  2.6962e-01, -3.0867e-03, -8.8386e-01,  2.1381e-01,\n",
       "          3.5224e-01, -6.3867e-01,  1.0000e+00, -4.8712e-01, -9.8675e-01,\n",
       "          6.3625e-01,  4.9007e-01,  5.4894e-01,  1.0124e-01,  1.8784e-01,\n",
       "         -1.0000e+00,  4.5278e-01, -1.8796e-01, -9.9395e-01,  4.5648e-01,\n",
       "          6.3156e-01, -3.7114e-01,  2.5701e-01,  6.2616e-01, -3.9234e-01,\n",
       "         -5.4888e-01, -4.5939e-01, -5.8156e-01, -3.7152e-01, -3.1974e-01,\n",
       "          2.1069e-01, -2.8905e-01, -4.6719e-01, -4.5306e-01,  3.7716e-01,\n",
       "         -6.3859e-01, -4.8856e-01,  6.1397e-01,  4.1256e-02,  7.3290e-01,\n",
       "          4.9843e-01, -5.2171e-01,  4.6938e-01, -9.6573e-01,  7.0322e-01,\n",
       "         -4.1360e-01, -9.9016e-01, -5.8704e-01, -9.9285e-01,  7.4242e-01,\n",
       "         -4.3315e-01, -1.6181e-01,  9.7972e-01,  2.6001e-01,  5.1281e-01,\n",
       "         -1.8550e-01, -7.3783e-01, -1.0000e+00, -6.0257e-01, -5.1859e-01,\n",
       "         -2.2795e-01, -3.9188e-01, -9.8128e-01, -9.8024e-01,  7.0347e-01,\n",
       "          9.6251e-01,  3.3708e-01,  9.9980e-01, -4.1686e-01,  9.6302e-01,\n",
       "         -1.2493e-01, -6.3016e-01,  3.6341e-01, -6.2117e-01,  7.2084e-01,\n",
       "          3.3516e-01, -6.0973e-01,  3.9416e-01, -5.6812e-01,  1.8756e-01,\n",
       "         -6.7733e-01, -3.0403e-01, -4.5222e-01, -9.5926e-01, -5.1616e-01,\n",
       "          9.6961e-01, -4.5619e-01, -8.2515e-01,  2.9239e-01, -3.4380e-01,\n",
       "         -6.0823e-01,  8.5012e-01,  7.1405e-01,  4.8366e-01, -3.0571e-01,\n",
       "          5.1850e-01,  9.4647e-02,  6.6954e-01, -8.5478e-01,  1.2909e-02,\n",
       "          5.4378e-01, -3.9454e-01, -6.1619e-01, -9.8474e-01, -3.8408e-01,\n",
       "          5.8612e-01,  9.9254e-01,  8.0797e-01,  3.6991e-01,  5.4770e-01,\n",
       "         -4.7578e-01,  6.2710e-01, -9.6163e-01,  9.8600e-01, -2.4664e-01,\n",
       "          4.5559e-01, -5.2337e-01,  1.0180e-01, -8.9734e-01, -1.3027e-01,\n",
       "          8.1790e-01, -6.3834e-01, -8.6655e-01, -2.3403e-01, -6.1399e-01,\n",
       "         -4.8277e-01, -7.4117e-01,  4.3834e-01, -3.0976e-01, -5.0087e-01,\n",
       "         -1.8366e-01,  9.6053e-01,  9.7454e-01,  8.0647e-01, -2.2958e-01,\n",
       "          6.3029e-01, -9.3344e-01, -5.8088e-01,  1.9864e-01,  3.4024e-01,\n",
       "          2.2674e-01,  9.9490e-01, -6.8087e-01, -1.7863e-01, -9.5505e-01,\n",
       "         -9.9105e-01,  4.4006e-02, -9.1703e-01, -2.7743e-01, -7.8725e-01,\n",
       "          7.3592e-01, -3.2977e-01,  3.7870e-01,  5.7388e-01, -9.8495e-01,\n",
       "         -8.1288e-01,  5.2758e-01, -5.6284e-01,  5.0384e-01, -4.4858e-01,\n",
       "          8.8115e-01,  7.9988e-01, -7.0561e-01,  6.9819e-01,  9.4207e-01,\n",
       "         -7.9971e-01, -8.4508e-01,  7.9408e-01, -3.8257e-01,  8.7581e-01,\n",
       "         -7.3250e-01,  9.8351e-01,  8.9237e-01,  7.8765e-01, -9.3686e-01,\n",
       "         -4.5550e-01, -8.6463e-01, -3.6324e-01, -1.2287e-01, -1.0218e-01,\n",
       "          7.1399e-01,  6.7811e-01,  4.9252e-01,  5.7220e-01, -6.2799e-01,\n",
       "          9.9611e-01, -8.9721e-01, -9.6505e-01, -3.8495e-01, -2.7822e-01,\n",
       "         -9.9153e-01,  5.8297e-01,  3.7366e-01,  3.0702e-01, -4.7548e-01,\n",
       "         -7.4614e-01, -9.7549e-01,  8.5473e-01,  2.5895e-01,  9.8568e-01,\n",
       "         -4.2271e-01, -9.0982e-01, -5.5229e-01, -9.4946e-01,  7.4584e-02,\n",
       "         -3.2965e-01, -3.5629e-03,  3.4150e-02, -9.7168e-01,  5.6627e-01,\n",
       "          6.8718e-01,  6.5170e-01, -3.6174e-01,  9.9837e-01,  1.0000e+00,\n",
       "          9.8448e-01,  9.1794e-01,  9.1281e-01, -9.9945e-01, -5.0951e-01,\n",
       "          9.9999e-01, -9.7806e-01, -1.0000e+00, -9.4702e-01, -6.8819e-01,\n",
       "          6.3595e-01, -1.0000e+00, -2.9973e-01, -1.3208e-01, -9.4640e-01,\n",
       "          3.2752e-01,  9.8073e-01,  9.9218e-01, -1.0000e+00,  8.2681e-01,\n",
       "          9.5585e-01, -6.8125e-01,  9.4305e-01, -5.2470e-01,  9.7760e-01,\n",
       "          5.5733e-01,  5.1857e-01, -3.6643e-01,  4.8503e-01, -8.4581e-01,\n",
       "         -8.8786e-01, -1.1906e-01, -5.5627e-01,  9.9591e-01,  1.8954e-01,\n",
       "         -7.3598e-01, -9.2652e-01,  5.6862e-01, -2.4431e-01, -1.9539e-01,\n",
       "         -9.7758e-01, -3.9243e-01,  1.3624e-01,  8.2047e-01,  2.8170e-01,\n",
       "          4.2030e-01, -7.1532e-01,  3.3992e-01, -3.1043e-01,  3.7113e-01,\n",
       "          7.3487e-01, -9.4190e-01, -5.7637e-01, -1.3452e-01, -4.8373e-01,\n",
       "         -3.7234e-01, -9.7855e-01,  9.7458e-01, -3.8401e-01,  7.2059e-01,\n",
       "          1.0000e+00,  1.5641e-02, -9.1463e-01,  7.1908e-01,  3.9233e-01,\n",
       "         -5.6026e-01,  1.0000e+00,  7.5391e-01, -9.8249e-01, -6.0320e-01,\n",
       "          5.1653e-01, -6.1394e-01, -6.9467e-01,  9.9941e-01, -3.0191e-01,\n",
       "         -4.7055e-01, -2.8472e-01,  9.8620e-01, -9.9188e-01,  9.8973e-01,\n",
       "         -9.3448e-01, -9.8079e-01,  9.7757e-01,  9.5667e-01, -4.8148e-01,\n",
       "         -6.2561e-01,  1.7195e-01, -4.9479e-01,  3.3495e-01, -9.4863e-01,\n",
       "          6.8228e-01,  5.9958e-01, -3.0581e-01,  9.2804e-01, -8.4223e-01,\n",
       "         -6.4510e-01,  3.7195e-01, -2.9762e-01,  8.5629e-02,  7.7748e-01,\n",
       "          5.8732e-01, -3.2130e-01,  1.5741e-01, -3.5500e-01, -8.0875e-01,\n",
       "         -9.8465e-01,  4.9467e-01,  1.0000e+00, -2.5208e-01,  6.8677e-01,\n",
       "         -3.6728e-01, -1.6167e-01, -1.5196e-02,  5.6554e-01,  6.7572e-01,\n",
       "         -4.8823e-01, -8.6361e-01,  5.4968e-01, -9.6473e-01, -9.9101e-01,\n",
       "          7.3140e-01,  3.5938e-01, -3.9520e-01,  9.9999e-01,  3.6676e-01,\n",
       "          3.5781e-01,  4.8180e-02,  9.6504e-01,  1.4751e-01,  5.7776e-01,\n",
       "          5.9114e-01,  9.8671e-01, -2.9635e-01,  5.9098e-01,  8.1554e-01,\n",
       "         -7.1213e-01, -4.4731e-01, -7.5796e-01,  1.7954e-01, -9.4083e-01,\n",
       "          5.5489e-03, -9.6336e-01,  9.7379e-01,  8.2011e-01,  5.1676e-01,\n",
       "          3.0101e-01,  5.9827e-01,  1.0000e+00, -6.5822e-01,  6.0617e-01,\n",
       "         -1.5470e-01,  7.8068e-01, -9.9922e-01, -8.5633e-01, -5.6557e-01,\n",
       "         -2.1692e-01, -5.5610e-01, -4.8669e-01,  3.8241e-01, -9.7519e-01,\n",
       "          6.0919e-01,  4.6190e-01, -9.8667e-01, -9.9131e-01,  1.8227e-01,\n",
       "          8.5775e-01,  2.5318e-01, -9.7473e-01, -7.9037e-01, -7.1373e-01,\n",
       "          6.2217e-01, -3.3045e-01, -9.6047e-01,  2.1692e-01, -4.1324e-01,\n",
       "          5.3249e-01, -2.6093e-01,  5.9373e-01,  6.4430e-01,  7.4910e-01,\n",
       "         -4.8575e-01, -2.9382e-01, -1.4688e-01, -8.2378e-01,  8.6281e-01,\n",
       "         -8.0631e-01, -8.3826e-01, -3.8678e-01,  1.0000e+00, -5.9083e-01,\n",
       "          6.9667e-01,  7.6828e-01,  6.4100e-01, -2.9527e-01,  3.9455e-01,\n",
       "          7.4890e-01,  3.6851e-01, -4.2948e-01, -6.1293e-01, -2.5631e-01,\n",
       "         -4.4670e-01,  6.9251e-01,  2.7942e-01,  4.7213e-01,  8.4137e-01,\n",
       "          8.0493e-01,  2.2305e-01, -2.0945e-01,  1.7895e-01,  9.9932e-01,\n",
       "         -2.0142e-01, -6.0381e-02, -4.1075e-01, -2.0877e-01, -4.8352e-01,\n",
       "         -3.2870e-01,  1.0000e+00,  4.0827e-01,  2.8886e-01, -9.9271e-01,\n",
       "         -7.9692e-01, -9.3989e-01,  1.0000e+00,  8.6094e-01, -7.5155e-01,\n",
       "          6.4501e-01,  4.9711e-01, -3.7966e-01,  7.7264e-01, -3.0235e-01,\n",
       "         -3.6751e-01,  3.7996e-01,  2.8905e-01,  9.7425e-01, -6.2888e-01,\n",
       "         -9.7981e-01, -6.0696e-01,  5.4997e-01, -9.7897e-01,  9.9973e-01,\n",
       "         -6.3892e-01, -3.7734e-01, -5.8260e-01, -3.3845e-01,  1.4508e-01,\n",
       "          2.4577e-02, -9.8841e-01, -3.8670e-01,  2.7736e-01,  9.7714e-01,\n",
       "          3.5239e-01, -5.8228e-01, -9.0886e-01,  4.1479e-01,  5.6257e-01,\n",
       "         -7.3049e-01, -9.4838e-01,  9.7495e-01, -9.8932e-01,  6.3745e-01,\n",
       "          1.0000e+00,  5.2209e-01, -2.9781e-01,  3.6075e-01, -4.6275e-01,\n",
       "          4.0711e-01,  9.6010e-02,  7.5125e-01, -9.7268e-01, -4.9665e-01,\n",
       "         -3.3943e-01,  3.5119e-01, -1.9835e-01,  1.1748e-01,  7.3860e-01,\n",
       "          3.7909e-01, -5.9969e-01, -6.8528e-01, -1.9799e-01,  4.9386e-01,\n",
       "          8.1439e-01, -3.7042e-01, -1.9150e-01,  1.4526e-01, -2.4845e-01,\n",
       "         -9.4175e-01, -3.6681e-01, -5.0099e-01, -9.9999e-01,  7.1111e-01,\n",
       "         -1.0000e+00,  2.6982e-01, -8.2429e-02, -4.2822e-01,  8.4133e-01,\n",
       "          6.1524e-01,  5.3579e-01, -8.0613e-01, -6.6005e-01,  6.9741e-01,\n",
       "          7.8097e-01, -3.7539e-01, -2.1155e-01, -7.7767e-01,  3.4115e-01,\n",
       "         -2.4944e-01,  2.9336e-01, -4.1770e-01,  7.7793e-01, -3.3813e-01,\n",
       "          1.0000e+00,  2.6798e-01, -7.0659e-01, -9.7222e-01,  3.0744e-01,\n",
       "         -3.6380e-01,  1.0000e+00, -8.8727e-01, -9.6609e-01,  4.8749e-01,\n",
       "         -7.8017e-01, -8.4960e-01,  4.2798e-01,  1.0813e-01, -7.6948e-01,\n",
       "         -8.5687e-01,  9.7139e-01,  8.1815e-01, -5.5916e-01,  5.5484e-01,\n",
       "         -4.0150e-01, -5.9488e-01,  1.5159e-01,  6.5804e-01,  9.9125e-01,\n",
       "          5.7455e-01,  9.2443e-01,  1.3084e-01, -3.1333e-01,  9.8234e-01,\n",
       "          2.7211e-01,  2.6429e-01,  2.5695e-01,  1.0000e+00,  4.5515e-01,\n",
       "         -9.3002e-01,  2.3446e-01, -9.8289e-01, -3.2291e-01, -9.4471e-01,\n",
       "          3.4719e-01,  2.5608e-01,  9.2847e-01, -3.4356e-01,  9.6828e-01,\n",
       "         -5.0153e-01,  1.1798e-01, -3.1436e-01, -1.7563e-01,  4.3856e-01,\n",
       "         -9.4030e-01, -9.9180e-01, -9.8707e-01,  5.3152e-01, -4.8776e-01,\n",
       "         -1.2404e-01,  3.4022e-01,  2.2188e-01,  5.7402e-01,  4.8835e-01,\n",
       "         -1.0000e+00,  9.4575e-01,  5.4814e-01,  7.5183e-01,  9.7677e-01,\n",
       "          6.1774e-01,  4.3506e-01,  3.8075e-01, -9.8891e-01, -9.8328e-01,\n",
       "         -4.7207e-01, -3.6387e-01,  7.3456e-01,  7.5640e-01,  9.0889e-01,\n",
       "          5.2455e-01, -5.8949e-01, -6.1679e-01, -1.2561e-01, -7.5196e-01,\n",
       "         -9.9392e-01,  6.2306e-01, -2.3191e-01, -9.5056e-01,  9.6471e-01,\n",
       "         -5.1871e-01, -3.5134e-01,  2.3073e-01, -6.6179e-01,  9.0648e-01,\n",
       "          7.9934e-01,  3.7645e-01,  2.1190e-01,  4.9208e-01,  8.9754e-01,\n",
       "          9.3734e-01,  9.8673e-01, -6.7084e-01,  8.0231e-01, -5.1932e-01,\n",
       "          5.2476e-01,  7.8676e-01, -9.4878e-01,  2.7215e-01,  5.2604e-01,\n",
       "         -3.3489e-01,  3.4138e-01, -3.3624e-01, -9.7247e-01,  5.1987e-01,\n",
       "         -3.4895e-01,  6.7773e-01, -5.6135e-01, -4.8615e-02, -5.3345e-01,\n",
       "         -2.5164e-01, -7.3167e-01, -7.3580e-01,  6.8081e-01,  6.1987e-01,\n",
       "          9.2298e-01,  8.1638e-01, -2.4862e-01, -7.2944e-01, -2.0521e-01,\n",
       "         -5.5680e-01, -9.3592e-01,  9.2429e-01, -1.5061e-01,  9.3914e-03,\n",
       "          6.5935e-01,  9.6373e-03,  8.8429e-01, -7.4856e-03, -4.2389e-01,\n",
       "         -4.3056e-01, -7.3231e-01,  8.9681e-01, -6.5420e-01, -5.9452e-01,\n",
       "         -6.5629e-01,  6.8895e-01,  5.2346e-01,  9.9995e-01, -5.5028e-01,\n",
       "         -6.8776e-01, -4.7497e-01, -5.0583e-01,  5.9387e-01, -4.6716e-01,\n",
       "         -1.0000e+00,  4.9493e-01, -2.2349e-01,  6.0399e-01, -5.3220e-01,\n",
       "          6.2007e-01, -5.7161e-01, -9.8009e-01, -4.1158e-01,  5.6115e-01,\n",
       "          5.5261e-01, -6.1893e-01, -4.6287e-01,  6.0444e-01,  1.2595e-01,\n",
       "          9.4328e-01,  8.8118e-01, -5.6112e-01,  4.9570e-01,  6.8444e-01,\n",
       "         -7.3466e-01, -7.6556e-01,  9.3784e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = output.last_hidden_state\n",
    "pooled_output = output.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2026,  2171,  2003, 10654,  4143,   102]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1111,  0.5129, -0.2334,  ..., -0.1131,  0.0528,  0.4727],\n",
       "         [ 0.0246, -0.1088, -0.6136,  ..., -0.2063, -0.0297,  0.1686],\n",
       "         [-0.3681,  0.4598,  0.0354,  ..., -0.3725,  0.2379,  0.1640],\n",
       "         ...,\n",
       "         [-0.1694,  0.1914, -0.0478,  ..., -0.6429, -0.2118, -0.3504],\n",
       "         [-0.3843, -0.3724, -0.4704,  ...,  0.5174, -0.0247, -0.5458],\n",
       "         [ 0.8794,  0.0940, -0.3478,  ...,  0.1397, -0.7686, -0.2198]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [7, 768].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output1\u001b[38;5;241m=\u001b[39m\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_hidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:979\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    978\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 979\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [7, 768].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "output1=bert_model(last_hidden_states[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
